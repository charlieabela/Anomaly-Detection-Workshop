{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42f6561",
   "metadata": {},
   "source": [
    "# Notebook 1 – Statistical Foundations of Anomaly Detection  \n",
    "*Generated 2025-05-13*\n",
    "\n",
    "This guided notebook complements **Slides 1‑20** of the deck, covering the statistical core of anomaly detection.\n",
    "\n",
    "> Work in pairs: swap driver/navigator roles at each 🛑 checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca726a8",
   "metadata": {},
   "source": [
    "## 1️⃣ What is Anomaly Detection?\n",
    "\n",
    "*Anomaly* ≈ observation that **deviates** so much from other observations that it arouses suspicions it was generated by a **different mechanism**.\n",
    "\n",
    "### Real‑world examples\n",
    "| Domain | Anomaly instance |\n",
    "|--------|------------------|\n",
    "| Finance | Sudden $9 999 charge on dormant card |\n",
    "| Health | Irregular heart‑rate spike in ECG |\n",
    "| Cybersecurity | 50 login attempts from a new IP in 10 s |\n",
    "\n",
    "### Taxonomy of anomalies\n",
    "| Type | Description | Example |\n",
    "|------|-------------|---------|\n",
    "| **Point** | Single data point abnormal in feature space | Fraudulent transaction amount |\n",
    "| **Contextual** | Normal globally, abnormal in local context | 18 °C reading in a boiler that’s usually 95 °C |\n",
    "| **Collective** | Group of points abnormal as a sequence | Slow exfiltration pattern across many small packets |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📥 Load the benchmark dataset\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "url = \"https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df['Class'].value_counts(normalize=True).rename({0:'Legit',1:'Fraud'}))\n",
    "\n",
    "# Separate features / label and scale\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec68a4",
   "metadata": {},
   "source": [
    "## 2️⃣ Univariate Robust Z‑Score\n",
    "\n",
    "For each feature $x$:\n",
    "\n",
    "$$ z = \\frac{|x - \\tilde{x}|}{\\text{MAD}} $$\n",
    "\n",
    "*Where*  \n",
    "\\( \\tilde{x} \\) = median  MAD = Median Absolute Deviation.\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "1. Compute *per‑feature* robust $z$.  \n",
    "2. Aggregate per row (sum).  \n",
    "3. Flag rows above a percentile threshold (e.g., 99.9 %).  \n",
    "\n",
    "**Strengths**\n",
    "\n",
    "* Simple, fast, interpretable.  \n",
    "* Robust median & MAD resist skewed data.\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "* Ignores feature correlation.  \n",
    "* Struggles with contextual/collective anomalies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f46e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import median_abs_deviation\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "med = X.median()\n",
    "mad = X.apply(median_abs_deviation).replace(0, 1e-6)\n",
    "z_scores = ((X - med) / mad).abs()\n",
    "df['z_sum'] = z_scores.sum(axis=1)\n",
    "\n",
    "# Threshold top 0.1%\n",
    "thresh = np.quantile(df['z_sum'], 0.999)\n",
    "pred_z = (df['z_sum'] > thresh).astype(int)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y, df['z_sum'])\n",
    "pr_auc_z = auc(recall, precision)\n",
    "print(f\"Robust Z‑score PR‑AUC: {pr_auc_z:.4f}\")\n",
    "\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "plt.title(\"Robust Z‑score – PR curve\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2934e4ae",
   "metadata": {},
   "source": [
    "### 📝 Interpreting the Robust Z‑score output\n",
    "\n",
    "* **PR‑AUC value** printed in the previous cell quantifies discrimination under extreme class imbalance.  \n",
    "  *A PR‑AUC close to 1.0 ⇒ almost perfect; 0.5 ⇒ random; <0.5 ⇒ worse than random.*\n",
    "\n",
    "* **Curve shape**  \n",
    "  * Steep initial rise* → method captures the *most obvious* anomalies with very high precision.  \n",
    "  * Sharp drop* → many false positives once threshold moves past the extreme tail.\n",
    "\n",
    "* **Threshold insight**  \n",
    "  The 99.9‑th percentile threshold flagged roughly 0.1 % of rows.  \n",
    "  If early precision is high but recall low, lowering the threshold (e.g. 99.7 %) would **recover more anomalies** at the cost of extra investigations.\n",
    "\n",
    "**Take‑away**: Robust Z‑score is a good *first‑pass* detector when anomalies are extreme univariate deviations, but correlation‑based anomalies will slip through.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2b196a",
   "metadata": {},
   "source": [
    "## 3️⃣ Multivariate Mahalanobis Distance\n",
    "\n",
    "$$ D_M(x) = \\sqrt{(x-\\mu)^T\\,\\Sigma^{-1}(x-\\mu)} $$\n",
    "\n",
    "*Where*  \n",
    "\\( \\mu \\) = mean vector  \\( \\Sigma \\)= covariance matrix.\n",
    "\n",
    "> Intuition: distance in **whitened** space accounts for feature variance *and* correlation.\n",
    "\n",
    "**Practical tips**\n",
    "\n",
    "* Need **n ≫ p** to get stable covariance.  \n",
    "* Use a **robust covariance estimator** (e.g., Ledoit‑Wolf) when outliers present.\n",
    "\n",
    "**Strengths**\n",
    "\n",
    "* Captures inter‑feature correlation.  \n",
    "* Parametric; threshold via chi‑square distribution.\n",
    "\n",
    "**Limitations**\n",
    "\n",
    "* Sensitive to ill‑conditioned covariance.  \n",
    "* Assumes elliptical clusters (multivariate normal).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821f7904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.covariance import LedoitWolf\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "# Fit robust covariance on scaled data\n",
    "cov_est = LedoitWolf().fit(X_scaled)\n",
    "inv_cov = cov_est.get_precision()\n",
    "mean_vec = X_scaled.mean(axis=0)\n",
    "\n",
    "mahal_d = np.array([mahalanobis(row, mean_vec, inv_cov) for row in X_scaled])\n",
    "df['mahal'] = mahal_d\n",
    "\n",
    "# Threshold top 0.1%\n",
    "thresh_m = np.quantile(df['mahal'], 0.999)\n",
    "pred_m = (df['mahal'] > thresh_m).astype(int)\n",
    "\n",
    "precision_m, recall_m, _ = precision_recall_curve(y, df['mahal'])\n",
    "pr_auc_m = auc(recall_m, precision_m)\n",
    "print(f\"Mahalanobis PR‑AUC: {pr_auc_m:.4f}\")\n",
    "\n",
    "plt.plot(recall_m, precision_m)\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "plt.title(\"Mahalanobis – PR curve\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8162047",
   "metadata": {},
   "source": [
    "### 📝 Interpreting the Mahalanobis output\n",
    "\n",
    "* **PR‑AUC & curve**  \n",
    "  Compare the reported AUC to the Z‑score’s.  A higher AUC means modelling covariance picked up multivariate outliers the univariate rule missed.\n",
    "\n",
    "* **Curve shape**  \n",
    "  Flatter precision early on?  Indicates Mahalanobis sometimes classifies *borderline* points as anomalous—common when covariance is estimated from mixed data.\n",
    "\n",
    "* **Data prerequisites**  \n",
    "  Stable Mahalanobis performance depends on **n ≫ p** and roughly elliptical normal class.  Examine if low AUC traces back to a poorly conditioned covariance matrix.\n",
    "\n",
    "**Implication**: Use Mahalanobis when correlation structure matters (e.g. velocity vs distance), but validate that covariance estimation is robust.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f7f8f3",
   "metadata": {},
   "source": [
    "## 4️⃣ Comparative Analysis\n",
    "\n",
    "Below we overlay the Precision‑Recall curves of both methods and summarise AUCs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(recall, precision, label=f\"Z‑score (AUC={pr_auc_z:.3f})\")\n",
    "plt.plot(recall_m, precision_m, label=f\"Mahalanobis (AUC={pr_auc_m:.3f})\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
    "plt.title(\"PR Comparison\")\n",
    "plt.legend()\n",
    "\n",
    "# Bar chart for quick comparison\n",
    "plt.figure()\n",
    "plt.bar([\"Z‑score\",\"Mahalanobis\"], [pr_auc_z, pr_auc_m])\n",
    "plt.ylabel(\"PR‑AUC\"); plt.title(\"AUC comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0a4824",
   "metadata": {},
   "source": [
    "### 📊 Comparative plot interpretation\n",
    "\n",
    "* **PR overlay** – Whichever curve sits *highest across most recall values* offers the best precision‑recall trade‑off overall.\n",
    "\n",
    "* **Bar chart**  \n",
    "  Quick numerical snapshot:  \n",
    "  *Δ AUC ≥ 0.05* is usually **practically significant**; smaller gaps may not justify a more complex method.\n",
    "\n",
    "* **Decision guideline**\n",
    "\n",
    "| Scenario | Preferred method |\n",
    "|----------|------------------|\n",
    "| Need **explainable rule** & anomalies are *extreme spikes* | Robust Z‑score |\n",
    "| Anomalies hide in *correlated feature space* | Mahalanobis |\n",
    "| Real‑time streaming, minimal compute | Z‑score (constant‑time update) |\n",
    "\n",
    "Always align the choice with domain cost of *false negatives* vs *false positives*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c83bc2",
   "metadata": {},
   "source": [
    "## 5️⃣ Knowledge Check – Discuss & Answer\n",
    "\n",
    "1. **Conceptual** – Give one real‑world example of a *contextual* anomaly and explain why a univariate Z‑score might miss it.  \n",
    "2. **Technical** – If the MAD of a feature is *zero*, what adjustment should you make before computing the Z‑score?  \n",
    "3. **Mahalanobis** – Why does multicollinearity in features risk inflating Mahalanobis distances?  \n",
    "4. **Thresholding** – Describe one data‑driven way (other than a fixed percentile) to choose an anomaly threshold.  \n",
    "5. **Critical thinking** – In our experiment, which method achieved higher PR‑AUC and what property of the dataset might explain this?\n",
    "\n",
    "> *Write your answers in the provided reflection sheet or discuss with your partner.*\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
